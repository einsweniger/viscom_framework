{
  "Shader": {
    "ver": "0.1",
    "info": {
      "id": "XtsSzH",
      "date": "1434504903",
      "viewed": 3267,
      "name": "Correct Picture Blurring",
      "username": "iq",
      "description": "The correct way to blur/downsample [b]pictures[/b] is to remove the gamma correction of the picture [b]before[/b] the linear transform and apply it again [b]after[/b] the transform. [url]http://iquilezles.org/www/articles/gamma/gamma.htm[/url]",
      "likes": 25,
      "published": 3,
      "flags": 0,
      "tags": [
        "2d",
        "blur",
        "gamma",
        "degamma"
      ],
      "hasliked": 0
    },
    "renderpass": [
      {
        "inputs": [
          {
            "id": 5,
            "src": "/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg",
            "ctype": "texture",
            "channel": 0,
            "sampler": {
              "filter": "mipmap",
              "wrap": "repeat",
              "vflip": "false",
              "srgb": "false",
              "internal": "byte"
            },
            "published": 1
          }
        ],
        "outputs": [
          {
            "id": 37,
            "channel": 0
          }
        ],
        "code": "// Created by inigo quilez - iq/2015\n// License Creative Commons Attribution-ShareAlike 3.0 Unported\n// https://creativecommons.org/licenses/by-sa/3.0/\n\n\n// The correct way to do blurring, convolution or downsampling for PICTURES is to \n// apply the gamma/degamma before the linear operations. Of course most people do\n// not apply the pow() for performanc reasons, but that is wrong:\n//\n// Notice how the image gets darker when the averaging is done with the raw pixel\n// values. However, when degammaing the colors prior to accumulation and applying\n// gamma after normalization, the image has no lose in brightness.\n//\n// Basically if x is your input picture, T your blurring/convolution/filter and y \n// you resulting image, instead of doing\n//\n// y = T( x )\n// \n// you should do \n//\n// y = G( T(G^-1(x)) )\n//\n// where G(x) is the expected gamma function (usually G(x) = x^2.2)\n//\n// More info here: http://iquilezles.org/www/articles/gamma/gamma.htm\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \n    // ------------------------------------------------------------\n    \n    // image downsampling/blurring/averaging\n    vec3 totWrong = vec3(0.0);\n    vec3 totCorrect = vec3(0.0);\n    \n    for( int j=0; j<9; j++ )\n    for( int i=0; i<9; i++ )\n    {\n        vec2 st = ( fragCoord.xy + vec2(float(i-4),float(j-4)) ) /iChannelResolution[0].xy;\n        vec3 co = texture( iChannel0, vec2(st.x,1.0-st.y) ).xyz;\n        \n        totWrong   += co;                // what most people do (incorrect)\n        totCorrect += pow(co,vec3(2.2)); // what you should do\n    }\n    \n    vec3 colWrong   = totWrong / 81.0;                    // what most people do (incorrect)\n    vec3 colCorrect = pow(totCorrect/81.0,vec3(1.0/2.2)); // what you should do\n\n\n    // ------------------------------------------------------------\n\n    // reference/original image\n    vec2 st = fragCoord.xy / iChannelResolution[0].xy;\n    vec3 colReference = texture( iChannel0, vec2(st.x,1.0-st.y) ).xyz;\n    \n    // final image\n    vec2 q = fragCoord.xy / iResolution.xy;\n    float th = 0.1 + 0.8*smoothstep(-0.1,0.1,sin(0.25*6.2831*iTime) );\n    vec3 col = mix( (q.y>th)?colWrong:colCorrect, colReference, smoothstep( -0.1, 0.1, sin(6.2831*iTime) ) );\n    col *= smoothstep( 0.005, 0.006, abs(q.y-th) );\n        \n\tfragColor = vec4( col, 1.0 );\n}",
        "name": "Image",
        "description": "",
        "type": "image"
      }
    ]
  }
}